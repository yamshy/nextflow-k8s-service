apiVersion: v1
kind: ConfigMap
metadata:
  name: demo-workflow
  namespace: nextflow
data:
  demo.nf: |
    #!/usr/bin/env nextflow

    /*
     * Portfolio Demo Pipeline
     * Demonstrates parallel data processing with scatter-gather pattern
     */

    // Accept batch count parameter (1-12 range to fit within 50Gi/14 CPU quota)
    params.batches = 5

    process GENERATE {
        input:
        val batch_id

        output:
        path "batch_${batch_id}.csv"

        script:
        """
        #!/bin/bash
        set -euo pipefail
        echo "Generating batch ${batch_id}..."
        sleep 5
        for i in {1..100}; do
            echo "${batch_id},\$((RANDOM % 1000)),\$((RANDOM % 100))" >> batch_${batch_id}.csv
        done
        """
    }

    process ANALYZE {
        input:
        path datafile

        output:
        path "stats_${datafile}.json"

        script:
        """
        #!/bin/bash
        set -euo pipefail
        sleep 3
        lines=\$(wc -l < ${datafile})
        sum=\$(awk -F',' '{s+=\$2} END {print (s ? s : 0)}' ${datafile})
        avg=\$(awk -F',' '{s+=\$2; n++} END {if (n>0) print s/n; else print 0}' ${datafile})
        echo '{"file":"${datafile}","lines":'\$lines',"sum":'\$sum',"average":'\$avg'}' > stats_${datafile}.json
        """
    }

    process REPORT {
        // Use workflow.runName to create unique output directories per run
        publishDir "/workspace/results/${workflow.runName}", mode: 'copy'

        input:
        path stats

        output:
        path "report.json"

        script:
        """
        #!/bin/bash
        set -euo pipefail
        total_batches=\$(echo ${stats} | wc -w)
        echo '{"batches":[' > report.json
        paste -sd ',' ${stats} >> report.json
        echo '],"timestamp":"'\$(date -Iseconds)'","total_batches":'\$total_batches'}' >> report.json
        """
    }

    workflow {
        // Scatter phase: Create parallel channel of batch IDs (1..N)
        // Each batch will be processed independently by GENERATE
        batches = Channel.of(1..params.batches)

        // Scatter-gather step 1: Generate data in parallel
        // Each GENERATE task runs concurrently (limited by K8s resources)
        data = GENERATE(batches)

        // Scatter-gather step 2: Analyze each batch independently
        // ANALYZE processes run in parallel, one per batch
        stats = ANALYZE(data)

        // Gather phase: Collect all stats files and aggregate into single report
        // .collect() waits for ALL stats files before proceeding to REPORT
        REPORT(stats.collect())
    }

  nextflow.config: |
    manifest {
        name = 'Portfolio Demo Pipeline'
        description = 'Parallel data processing demonstration for portfolio showcase'
        version = '1.0.0'
        author = 'Portfolio Showcase'
    }

    params {
        batches = 5
    }

    // Process configuration optimized for homelab (50Gi/14 CPU quota)
    process {
        executor = 'k8s'
        container = 'nextflow/nextflow:25.04.7'
        cpus = 1
        memory = '4 GB'
    }

    // K8s-specific configuration
    k8s {
        namespace = 'nextflow'
        serviceAccount = 'nextflow-runner'
        storageClaimName = 'nextflow-work-pvc'
        storageMountPath = '/workspace'
        cpuLimits = '1'
        memoryLimits = '4Gi'
    }

    // Resource limits aligned with homelab quota
    params {
        max_cpus = 1
        max_memory = '4 GB'
    }
